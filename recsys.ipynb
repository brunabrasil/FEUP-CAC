{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise import Dataset, Reader, accuracy, NormalPredictor, KNNBasic, SVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from utils import load_filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major variables\n",
    "\n",
    "city = 'Springfield'\n",
    "city_data = load_filtered_data(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame of business reviews by users\n",
    "\n",
    "reviews = city_data['review'][['review_id', 'business_id', 'user_id', 'stars']]\n",
    "reviews = reviews.groupby(['user_id', 'business_id'])['stars'].mean().reset_index()\n",
    "reviews.columns = ['user_id', 'business_id', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of ratings\n",
    "\n",
    "len(reviews['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of users who have reviewed\n",
    "\n",
    "len(reviews['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings statistics\n",
    "\n",
    "reviews['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings distribution\n",
    "\n",
    "reviews['rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-business matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city matrix\n",
    "\n",
    "city_matrix = reviews.pivot(index='user_id', columns='business_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_matrix.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city matrix sparsity\n",
    "\n",
    "print(f\"{city_matrix.notnull().sum().sum() / (city_matrix.shape[0] * city_matrix.shape[1]):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of total number of items per user\n",
    "\n",
    "businesses_per_user = city_matrix.notnull().sum(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(businesses_per_user, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Total Number of Businesses per User')\n",
    "plt.xlabel('Number of Businesses per User')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of total number of users per business\n",
    "\n",
    "users_per_business = city_matrix.notnull().sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(users_per_business, bins=50, color='lightgreen', edgecolor='black')\n",
    "plt.title('Distribution of Total Number of Users per Business')\n",
    "plt.xlabel('Number of Users per Business')\n",
    "plt.ylabel('Number of Businesses')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of mean ratings per user\n",
    "\n",
    "mean_ratings_per_user = city_matrix.mean(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(mean_ratings_per_user, bins=50, color='orange', edgecolor='black')\n",
    "plt.title('Distribution of Mean Ratings per User')\n",
    "plt.xlabel('Mean Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-business matrix for each community\n",
    "\n",
    "connection = 'priority_combined'\n",
    "with open(f'communities/{city}_{connection}_communities.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "community_matrices = {}\n",
    "for i, community in enumerate(data['communities']):\n",
    "    community_matrices[i] = reviews[reviews['user_id'].isin(community)]\n",
    "    community_matrices[i] = community_matrices[i].pivot_table(index='user_id', columns='business_id', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_matrices[0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sparsity\n",
    "\n",
    "sparsity = {}\n",
    "\n",
    "for community_id, matrix in community_matrices.items():\n",
    "    sparsity[community_id] = matrix.notnull().sum().sum() / (matrix.shape[0] * matrix.shape[1])\n",
    "\n",
    "for community_id, sparsity_value in sparsity.items():\n",
    "    print(f\"Community {community_id}: {sparsity_value:.2%} sparsity\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(sparsity.values(), bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Sparsity per Community')\n",
    "plt.xlabel('Sparsity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_trainsets = {}\n",
    "community_testsets = {}\n",
    "\n",
    "for community_id, matrix in community_matrices.items():\n",
    "    matrix_filtered = matrix[matrix >= 3].dropna(axis=0, how='all')\n",
    "\n",
    "    user_review_counts = matrix_filtered.apply(lambda row: row.count(), axis=1)\n",
    "    users_with_min_reviews = user_review_counts[user_review_counts >= 3].index.tolist()\n",
    "    print(user_review_counts)\n",
    "    matrix_filtered = matrix_filtered.loc[users_with_min_reviews]\n",
    "    df = matrix_filtered.stack().reset_index()\n",
    "    df.columns = ['user_id', 'business_id', 'rating']\n",
    "\n",
    "    trainset = defaultdict(list)\n",
    "    testset = defaultdict(list)\n",
    "    for user_id, group in df.groupby('user_id'):\n",
    "        num_reviews = len(group)\n",
    "        train_size = int(num_reviews * 0.8)\n",
    "        train_reviews = group[:train_size]\n",
    "        test_reviews = group[train_size:]\n",
    "        trainset[community_id].extend(train_reviews.values.tolist())\n",
    "        testset[community_id].extend(test_reviews.values.tolist())\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_data = Dataset.load_from_df(pd.DataFrame(trainset[community_id], columns=['user_id', 'business_id', 'rating']), reader)\n",
    "    test_data = Dataset.load_from_df(pd.DataFrame(testset[community_id], columns=['user_id', 'business_id', 'rating']), reader)\n",
    "\n",
    "    community_trainsets[community_id] = train_data.build_full_trainset()\n",
    "    community_testsets[community_id] = test_data.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a community trainset\n",
    "\n",
    "trainset = community_trainsets[0]\n",
    "for user_id, item_id, rating in trainset.all_ratings():\n",
    "    print(\"User:\", user_id, \"Item:\", item_id, \"Rating:\", rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a community testset\n",
    "\n",
    "testset = community_testsets[0]\n",
    "for user_id, item_id, rating in testset:\n",
    "    print(\"User:\", user_id, \"Item:\", item_id, \"Rating:\", rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainsets statistics\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    print(f\"Community {community_id}: {len(trainset.all_users())} users\")\n",
    "\n",
    "    businesses_per_user = [len(trainset.ur[user_id]) for user_id in trainset.all_users()]\n",
    "    print(f\"Average number of businesses per user: {np.mean(businesses_per_user):.2f}\")\n",
    "\n",
    "    users_per_business = [len(trainset.ir[business_id]) for business_id in trainset.all_items()]\n",
    "    print(f\"Average number of users per business: {np.mean(users_per_business):.2f}\")\n",
    "\n",
    "    mean_ratings_per_user = [np.mean([ratings for (_, ratings) in trainset.ur[user_id]]) for user_id in trainset.all_users()]\n",
    "    print(f\"Average mean ratings per user: {np.mean(mean_ratings_per_user):.2f}\")\n",
    "\n",
    "    ratings_distribution = [ratings for (_, _, ratings) in trainset.all_ratings()]\n",
    "    print(f\"Average ratings: {np.mean(ratings_distribution):.2f}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 most popular businesses in each community\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    business_ratings_count = Counter([len(trainset.ir[business_id]) for business_id in trainset.all_items()])\n",
    "    most_popular_businesses = business_ratings_count.most_common(5)\n",
    "\n",
    "\n",
    "    print(f\"\\nMost popular businesses in Community {community_id}:\")\n",
    "    for business_id, count in most_popular_businesses:\n",
    "        print(f\"Business ID: {business_id}, Number of Ratings: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_recommendations(trainset, top_n=10):\n",
    "    '''\n",
    "    Returns the top n most popular businesses in the trainset (number of reviews and average rating)\n",
    "    '''\n",
    "    business_counts = defaultdict(int)\n",
    "    business_ratings = defaultdict(float)\n",
    "\n",
    "    for _, business_id, _ in trainset.all_ratings():\n",
    "        business_counts[business_id] += 1\n",
    "        business_ratings[business_id] += rating\n",
    "\n",
    "    popular_businesses = []\n",
    "\n",
    "    for business_id, count in business_counts.items():\n",
    "        avg_rating = business_ratings[business_id] / count if count > 0 else 0\n",
    "        popularity_score = (count*0.2 + avg_rating*0.8) / 2\n",
    "        popular_businesses.append((business_id, popularity_score))\n",
    "\n",
    "    popular_businesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n = popular_businesses[:top_n]\n",
    "    return [trainset.to_raw_iid(i) for i, _ in top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular businesses in each community\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    popular_businesses = popular_recommendations(trainset, 5)\n",
    "    print(f\"Community {community_id}: {popular_businesses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(algo, trainset, testset):\n",
    "    '''\n",
    "    Evaluate the algorithm using RMSE\n",
    "    '''\n",
    "    if (len(trainset.all_users()) == 0) or (len(trainset.all_items()) == 0):\n",
    "        print('No data.')\n",
    "        return None\n",
    "    \n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    print(predictions)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random recommender for each community\n",
    "\n",
    "random_algo = NormalPredictor()\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    testset = community_testsets[community_id]\n",
    "    random_rmse = evaluate_algorithm(random_algo, trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-based collaborative filtering for each community\n",
    "\n",
    "ubcf_algo = KNNBasic(sim_options={'user_based': True})\n",
    "user_recommendations = {}\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    testset = community_testsets[community_id]\n",
    "    #ubcf_rmse = evaluate_algorithm(ubcf_algo, trainset, testset)\n",
    "    ubcf_algo.fit(trainset)\n",
    "    predictions = ubcf_algo.test(testset)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in user_recommendations:\n",
    "            user_recommendations[uid] = []\n",
    "        user_recommendations[uid].append((iid, est))\n",
    "    \n",
    "    \n",
    "\n",
    "for user_id, recommendations in user_recommendations.items():\n",
    "    print(\"User:\", user_id)\n",
    "    for business_id, rating in recommendations:\n",
    "        print(\"Business:\", business_id, \"Estimated Rating:\", rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-based collaborative filtering for each community\n",
    "\n",
    "ibcf_algo = KNNBasic(sim_options={'user_based': False})\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    testset = community_testsets[community_id]\n",
    "    ibcf_rmse = evaluate_algorithm(ibcf_algo, trainset, testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition (SVD) for each community\n",
    "svd_recommendations = {}\n",
    "\n",
    "svd_algo = SVD()\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    testset = community_testsets[community_id]\n",
    "    #svd_rmse = evaluate_algorithm(svd_algo, trainset, testset)\n",
    "\n",
    "    svd_algo.fit(trainset)\n",
    "    predictions = svd_algo.test(testset)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in svd_recommendations:\n",
    "            svd_recommendations[uid] = []\n",
    "        svd_recommendations[uid].append((iid, est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n(algo, trainset, user_id, n=10):\n",
    "    '''\n",
    "    Recommend top n items for a user using a recommender model\n",
    "    '''\n",
    "    user_ratings = trainset.ur[user_id]\n",
    "    items = [item_id for (item_id, _) in user_ratings]\n",
    "    item_scores = {}\n",
    "    # this is actually not the most correct way to do this, but it works\n",
    "    for item_id in trainset.all_items():\n",
    "        if item_id not in items:\n",
    "            prediction = algo.predict(trainset.to_raw_uid(user_id), trainset.to_raw_iid(item_id), verbose=True)\n",
    "            item_scores[item_id] = prediction.est\n",
    "    \n",
    "    top_items = sorted(item_scores, key=item_scores.get, reverse=True)[:n]\n",
    "    \n",
    "    return [trainset.to_raw_iid(i) for i in top_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major variables\n",
    "\n",
    "community_id = 0\n",
    "n = 5\n",
    "pos_rating = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendations for each user in the community\n",
    "\n",
    "# for user_id, recommendations in community_recommendations.items():\n",
    "#     print(f\"User {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert testsets to dataframes\n",
    "\n",
    "community_test_dfs = {}\n",
    "for community_id, testset in community_testsets.items():\n",
    "    community_test_dfs[community_id] = pd.DataFrame(testset, columns=['user_id', 'item_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate top recommendations for each user in a community\n",
    "\n",
    "community_recommendations = {}\n",
    "for index in range(len(community_trainsets[community_id].all_users())):\n",
    "    user_id = community_trainsets[community_id].all_users()[index]\n",
    "    recommendations = recommend_top_n(svd_algo, community_trainsets[0], user_id, n)\n",
    "    community_recommendations[user_id] = recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_test_dfs[0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of number of ratings per user in each community\n",
    "\n",
    "for community_id, test_df in community_test_dfs.items():\n",
    "    user_rating_counts = test_df.groupby(\"user_id\")['rating'].apply(len)\n",
    "    rating_count_distribution = user_rating_counts.value_counts()\n",
    "    print(f\"Community {community_id} - Distribution of Number of Ratings per User:\")\n",
    "    print(rating_count_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of users in the test set that exist in the train set\n",
    "\n",
    "for community_id, test_df in community_test_dfs.items():\n",
    "    df_testset_pos = test_df[test_df[\"rating\"] > pos_rating]\n",
    "    users = []\n",
    "    for u in df_testset_pos[\"user_id\"].unique():\n",
    "        try:\n",
    "            community_trainsets[community_id].to_inner_uid(u)\n",
    "            users.append(u)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Community {community_id}: Number of users in the test set that exist in the train set:\", len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate recommendations for each user in a community\n",
    "\n",
    "print(f\"Community {community_id} - Recommendations Evaluation:\")\n",
    "test_df = community_test_dfs[community_id]\n",
    "\n",
    "for user_id, recommendations in community_recommendations.items():\n",
    "    print(\"user_id:\", user_id)\n",
    "    gt = test_df[(test_df['user_id']==user_id) & (test_df['rating']>pos_rating)].item_id.to_list()\n",
    "    print(\"ground truth:\", gt)\n",
    "    print(\"recommendations:\", recommendations)\n",
    "    print(f\"hits: {len(set(gt).intersection(set(recommendations)))} / {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(city_data['review'], city_data['user'], on='user_id', how='left')\n",
    "merged = pd.merge(merged, city_data['business'], on='business_id', how='left')\n",
    "merged = merged.drop_duplicates(subset=['user_id', 'business_id'])\n",
    "\n",
    "merged.rename(columns={'stars_x': 'rating'}, inplace=True)\n",
    "merged.rename(columns={'stars_y': 'stars'}, inplace=True)\n",
    "\n",
    "merged = merged[['user_id', 'business_id', 'rating', 'categories', 'stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creates a column for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = set()\n",
    "\n",
    "for categories_list in merged['categories']:\n",
    "    x = categories_list.split(',')\n",
    "    for i in x:\n",
    "        all_categories.add(i.strip())\n",
    "\n",
    "category_columns = list(all_categories)\n",
    "\n",
    "category_df = pd.DataFrame(0, index=merged.index, columns=category_columns)\n",
    "\n",
    "for i, row in merged.iterrows():\n",
    "    for category in row['categories'].split(','):\n",
    "        category_df.at[i, category.strip()] = 1\n",
    "\n",
    "category_counts = category_df.sum()\n",
    "top_categories = category_counts.nlargest(200).index.to_list()\n",
    "\n",
    "merged = pd.concat([merged, category_df], axis=1)\n",
    "\n",
    "merged.drop('categories', axis=1, inplace=True)\n",
    "\n",
    "merged = merged.loc[:, (merged != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_trainsets_content = {}\n",
    "community_testsets_content = {}\n",
    "\n",
    "communities = {}\n",
    "\n",
    "for idx, community_users in enumerate(data['communities']):\n",
    "    communities[idx] = community_users\n",
    "\n",
    "for community_id, community in communities.items():    \n",
    "    community_reviews = merged[merged['user_id'].isin(community)]\n",
    "    community_reviews = community_reviews[community_reviews['rating'] >= 3]\n",
    "    user_review_counts = community_reviews.groupby('user_id').size()\n",
    "    user_review_counts = user_review_counts.reset_index()\n",
    "    user_review_counts.columns = ['user_id', 'review_count']\n",
    "\n",
    "    users_with_min_reviews = user_review_counts[user_review_counts['review_count'] >= 3]['user_id'].tolist()\n",
    "\n",
    "    merged_filtered = community_reviews[community_reviews['user_id'].isin(users_with_min_reviews)]\n",
    "\n",
    "    trainset = []\n",
    "    testset = []\n",
    "    for user_id, group in merged_filtered.groupby('user_id'):\n",
    "        num_reviews = len(group)\n",
    "        train_size = int(num_reviews * 0.7)\n",
    "        train_reviews = group[:train_size] \n",
    "        test_reviews = group[train_size:]  \n",
    "        trainset.append(train_reviews)\n",
    "        testset.append(test_reviews)\n",
    "\n",
    "    if trainset: \n",
    "        trainset_df = pd.concat(trainset)\n",
    "        community_trainsets_content[community_id] = trainset_df\n",
    "\n",
    "    if testset:  \n",
    "        testset_df = pd.concat(testset)\n",
    "        community_testsets_content[community_id] = testset_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendations( trainset, top_n=3):\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(trainset[[\"stars\",\"Watches\",\"Kids Hair Salons\",\"Soup\",\"Emergency Pet Hospital\",\"Bars\",\"Pressure Washers\",\"Car Window Tinting\",\"Tacos\",\"Chinese\",\"Occupational Therapy\",\"Knitting Supplies\",\"Disc Golf\",\"Coffee & Tea\",\"Donuts\",\"Physical Therapy\",\"Hair Stylists\",\"Boot Camps\",\"Desserts\",\"Eyelash Service\",\"Computers\",\"Italian\",\"Restaurants\",\"Senior Centers\",\"Mags\",\"Caterers\",\"Financial Advising\",\"Performing Arts\",\"Dry Cleaning\",\"Funeral Services & Cemeteries\",\"Bagels\",\"Car Dealers\",\"Trampoline Parks\",\"Cosmetic Surgeons\",\"Contractors\",\"Flowers & Gifts\",\"Sandwiches\",\"Amusement Parks\",\"Southern\",\"Country Clubs\",\"Cheesesteaks\",\"Shaved Ice\",\"Burgers\",\"Skin Care\",\"Tires\",\"Gold Buyers\",\"Recording & Rehearsal Studios\",\"Event Photography\",\"Weight Loss Centers\",\"Vietnamese\",\"Nail Salons\",\"Event Planning & Services\",\"Psychologists\",\"Hair Salons\",\"Auto Detailing\",\"Indoor Playcentre\",\"Specialty Schools\",\"Golf\",\"Body Shops\",\"Comfort Food\",\"Arcades\",\"Blow Dry/Out Services\",\"Employment Agencies\",\"Heating & Air Conditioning/HVAC\",\"Fitness & Instruction\",\"Hookah Bars\",\"Music & Video\",\"Office Equipment\",\"Junk Removal & Hauling\",\"Building Supplies\",\"Tobacco Shops\",\"Family Practice\",\"Mobile Phone Accessories\",\"Plumbing\",\"Photographers\",\"Men's Clothing\",\"Barbers\",\"Hardware Stores\",\"Middle Eastern\",\"Food Court\",\"Massage Therapy\",\"Pet Services\",\"Health Retreats\",\"Home Window Tinting\",\"Permanent Makeup\",\"Pubs\",\"Shoe Stores\",\"Shades & Blinds\",\"Electricians\",\"General Dentistry\",\"Real Estate Services\",\"Windshield Installation & Repair\",\"Fabric Stores\",\"Diagnostic Services\",\"Pest Control\",\"Discount Store\",\"Videos & Video Game Rental\",\"Sports Bars\",\"Fast Food\",\"Pretzels\",\"Dive Bars\",\"Grocery\",\"Reflexology\",\"Chicken Wings\",\"Kitchen & Bath\",\"Outlet Stores\",\"Plus Size Fashion\",\"Yoga\",\"Boxing\",\"Gas Stations\",\"Security Systems\",\"Dog Walkers\",\"Banks & Credit Unions\",\"Home Cleaning\",\"Gelato\",\"Steakhouses\",\"Sushi Bars\",\"Head Shops\",\"Custom Cakes\",\"Sports Clubs\",\"Pediatric Dentists\",\"Musical Instruments & Teachers\",\"Towing\",\"Home Theatre Installation\",\"Toy Stores\",\"Medical Centers\",\"Preschools\",\"Gymnastics\",\"Lingerie\",\"Cupcakes\",\"Professional Services\",\"Libraries\",\"Dentists\",\"Cocktail Bars\",\"Taiwanese\",\"Bespoke Clothing\",\"Candle Stores\",\"Books\",\"Automotive\",\"Nightlife\",\"Furniture Stores\",\"Arts & Crafts\",\"Endodontists\",\"Auto Repair\",\"Tanning\",\"Rugs\",\"Diners\",\"Jewelry Repair\",\"Printing Services\",\"Japanese\",\"Convenience Stores\",\"Fish & Chips\",\"Flooring\",\"Estate Planning Law\",\"Pharmacy\",\"Session Photography\",\"Travel Services\",\"Massage\",\"Breakfast & Brunch\",\"Home & Garden\",\"Insurance\",\"Holiday Decorations\",\"Security Services\",\"American (New)\",\"Tennis\",\"Eyewear & Opticians\",\"Health Markets\",\"Home Services\",\"Electronics Repair\",\"Food Delivery Services\",\"Oral Surgeons\",\"Gutter Services\",\"Pumpkin Patches\",\"Auto Loan Providers\",\"Jewelry\",\"Vintage & Consignment\",\"Real Estate\",\"Gyms\",\"Men's Hair Salons\",\"Framing\",\"Auto Parts & Supplies\",\"Counseling & Mental Health\",\"Juice Bars & Smoothies\",\"Fashion\",\"Bridal\",\"Generator Installation/Repair\",\"American (Traditional)\",\"Trainers\",\"Taxis\",\"Traditional Chinese Medicine\",\"Summer Camps\",\"Cheese Shops\",\"Laboratory Testing\",\"Shopping Centers\",\"Property Management\",\"Veterinarians\",\"Formal Wear\",\"Pediatricians\",\"Local Services\",\"Internet Service Providers\",\"Personal Injury Law\",\"Hotels & Travel\",\"Baby Gear & Furniture\",\"Party & Event Planning\",\"Salvadoran\",\"Landmarks & Historical Buildings\",\"Urgent Care\",\"Ramen\",\"Financial Services\",\"Signmaking\",\"Butcher\",\"Home Health Care\",\"Pets\",\"Women's Clothing\",\"Optometrists\",\"Noodles\",\"Cosmetic Dentists\",\"Personal Shopping\",\"Barbeque\",\"Used Car Dealers\",\"Shopping\",\"Art Classes\",\"Beer\",\"Florists\",\"Latin American\",\"Pool & Hot Tub Service\",\"Hospitals\",\"Oil Change Stations\",\"Cosmetology Schools\",\"Pizza\",\"Art Galleries\",\"Water Heater Installation/Repair\",\"Tanning Beds\",\"Hospice\",\"Gastropubs\",\"Buffets\",\"Makeup Artists\",\"Psychiatrists\",\"Farms\",\"Education\",\"Pet Sitting\",\"Seafood\",\"Videographers\",\"Shipping Centers\",\"Rehabilitation Center\",\"Candy Stores\",\"Commercial Truck Repair\",\"Drugstores\",\"Pet Stores\",\"Kids Activities\",\"Beer Bar\",\"Mexican\",\"Waffles\",\"Greek\",\"Waxing\",\"Mobile Phones\",\"Arts & Entertainment\",\"Specialty Food\",\"Telecommunications\",\"Transmission Repair\",\"Reiki\",\"Meat Shops\",\"Food\",\"Accessories\",\"Pasta Shops\",\"Laser Hair Removal\",\"Gift Shops\",\"Cosmetics & Beauty Supply\",\"Festivals\",\"Thai\",\"Beauty & Spas\",\"Vegetarian\",\"Hobby Shops\",\"Transportation\",\"Vape Shops\",\"Career Counseling\",\"Roadside Assistance\",\"Martial Arts\",\"Child Care & Day Care\",\"Appliances\",\"Delis\",\"Wine Bars\",\"Hotels\",\"Department Stores\",\"Carpeting\",\"Retirement Homes\",\"Day Spas\",\"Hair Extensions\",\"Lawyers\",\"Accountants\",\"Attraction Farms\",\"Indian\",\"IT Services & Computer Repair\",\"Ophthalmologists\",\"Bowling\",\"Dry Cleaning & Laundry\",\"Laundry Services\",\"Active Life\",\"Korean\",\"Roofing\",\"Children's Clothing\",\"Asian Fusion\",\"Post Offices\",\"Teeth Whitening\",\"Interior Design\",\"Pet Groomers\",\"Electronics\",\"Acupuncture\",\"Emergency Rooms\",\"Lounges\",\"Tex-Mex\",\"Bakeries\",\"Tui Na\",\"Sewing & Alterations\",\"Wine & Spirits\",\"Pet Training\",\"Wholesale Stores\",\"Sports Medicine\",\"Doctors\",\"Local Flavor\",\"Chicken Shop\",\"Ice Cream & Frozen Yogurt\",\"Orthodontists\",\"Lighting Fixtures & Equipment\",\"Art Supplies\",\"Mobile Phone Repair\",\"Salad\",\"Pet Boarding\",\"Health & Medical\",\"Hot Dogs\",\"Mattresses\",\"Cinema\",\"Dermatologists\",\"Nurseries & Gardening\",\"Nutritionists\",\"Prenatal/Perinatal Care\",\"Landscaping\",\"Eyebrow Services\",\"Tree Services\",\"Party Supplies\",\"Masonry/Concrete\",\"Notaries\",\"Public Services & Government\",\"Used\",\"Battery Stores\",\"Gluten-Free\",\"Home Automation\",\"Commercial Truck Dealers\",\"Spray Tanning\",\"Hot Tub & Pool\",\"Appliances & Repair\",\"Venues & Event Spaces\",\"Hair Removal\",\"Car Rental\",\"Auto Customization\",\"Auto Glass Services\",\"Painters\",\"Vitamins & Supplements\",\"Wheel & Rim Repair\",\"Home Decor\",\"Medical Spas\",\"Self Storage\",\"Car Wash\",\"Keys & Locksmiths\"]])\n",
    "    #similarity_matrix = cosine_similarity(trainset[top_categories])\n",
    "\n",
    "    community_recommendations = {}\n",
    "\n",
    "    for user_id, group in trainset.groupby('user_id'):\n",
    "        #user_ratings = set(group[group['rating'] >= 3]['business_id'])\n",
    "        user_ratings = set(group['business_id'])\n",
    "        user_recommendations = {}   \n",
    "        \n",
    "        for idx, (business_id, _) in enumerate(group[['business_id', 'rating']].values):\n",
    "            similar_indices = np.argsort(similarity_matrix[idx])[::-1][1:]\n",
    "            similar_businesses = [(trainset.iloc[sim_index]['business_id'], similarity_matrix[idx][sim_index]) for sim_index in similar_indices]\n",
    "            \n",
    "            for sim_business, sim_score in similar_businesses:\n",
    "                if sim_business not in user_ratings: \n",
    "                    if sim_business not in user_recommendations:\n",
    "                        user_recommendations[sim_business] = sim_score\n",
    "                    else:\n",
    "                        user_recommendations[sim_business] += sim_score\n",
    "        \n",
    "        user_top_recommendations = sorted(user_recommendations.keys(), key=lambda x: user_recommendations[x], reverse=True)[:top_n]\n",
    "        community_recommendations[user_id] = user_top_recommendations\n",
    "        \n",
    "    return community_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_rec_per_community = {}\n",
    "\n",
    "for community_id, community in communities.items():\n",
    "    if community_id in community_trainsets_content:\n",
    "        recommendation = content_based_recommendations(community_trainsets_content[community_id])\n",
    "        content_rec_per_community[community_id] = recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(community_test_dfs, recommendations_per_community, communities):\n",
    "    all_hits = 0\n",
    "    all_total = 0\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1 = []\n",
    "\n",
    "    for community_id, community in communities.items():\n",
    "        if community_id in community_trainsets_content:\n",
    "            test_df = community_test_dfs[community_id]\n",
    "            hits = 0\n",
    "            total = 0\n",
    "            total_gt = 0\n",
    "            for user_id, recommendations in recommendations_per_community[community_id].items():\n",
    "                gt = test_df[(test_df['user_id'] == user_id) & (test_df['rating'] >= 3)].item_id.to_list()\n",
    "                if len(recommendations) > 0 and len(gt) > 0:\n",
    "                    hits += len(set(gt).intersection(set(recommendations)))\n",
    "                    total += len(recommendations)\n",
    "                    total_gt += len(gt)\n",
    "            all_hits += hits\n",
    "            all_total += total\n",
    "            if total != 0:\n",
    "                precision = hits / total\n",
    "                recall = hits / total_gt\n",
    "                if precision + recall == 0:\n",
    "                    f1 = 0\n",
    "                else:\n",
    "                    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "                all_precisions.append(precision)\n",
    "                all_recalls.append(recall)\n",
    "                all_f1.append(f1)\n",
    "\n",
    "    overall_precision = np.mean(all_precisions) if all_precisions else 0\n",
    "    overall_recall = np.mean(all_recalls) if all_recalls else 0\n",
    "    overall_f1 = np.mean(all_f1) if all_f1 else 0\n",
    "\n",
    "    overall_hits_total = f\"{all_hits} / {all_total}\" if all_total != 0 else \"No test data\"\n",
    "\n",
    "    return overall_hits_total, overall_precision, overall_recall, overall_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Hits:\n",
      "19 / 1104\n",
      "Precision:\n",
      "0.030466631096883197\n",
      "Recall:\n",
      "0.07279509038598157\n",
      "F1:\n",
      "0.04241204151859029\n"
     ]
    }
   ],
   "source": [
    "community_hits, precisions, recall, f1 = calculate_precision(community_test_dfs, content_rec_per_community, communities)\n",
    "print(\"Community Hits:\")\n",
    "print(community_hits)\n",
    "print(\"Precision:\")\n",
    "print(precisions)\n",
    "print(\"Recall:\")\n",
    "print(recall)\n",
    "print(\"F1:\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid rec system (user based with content based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Join the user-based and content-based recommendations\n",
    "'''\n",
    "def join_recommendations(user_based, content_based, num_of_recommendations=3):\n",
    "    hybrid_recommendations = {}\n",
    "\n",
    "    for community_id, community_recommendations in content_based.items():\n",
    "        hybrid_recommendations[community_id] = {}\n",
    "        for user_id, user_based_rec in user_based.items():\n",
    "            content_rec = community_recommendations.get(user_id, [])  # Get content-based recommendations if available\n",
    "            combined_rec = []\n",
    "\n",
    "            common_businesses = set([rec[0] for rec in user_based_rec]).intersection(set(content_rec))\n",
    "            for rec in user_based_rec:\n",
    "                if rec[0] in common_businesses:\n",
    "                    combined_rec.append(rec[0])\n",
    "\n",
    "            for rec in user_based_rec:\n",
    "                if rec[0] not in common_businesses and len(combined_rec) < num_of_recommendations:\n",
    "                    combined_rec.append(rec[0])\n",
    "\n",
    "            for rec in content_rec:\n",
    "                if rec not in common_businesses and len(combined_rec) < num_of_recommendations:\n",
    "                    combined_rec.append(rec)\n",
    "\n",
    "\n",
    "            hybrid_recommendations[community_id][user_id] = combined_rec[:num_of_recommendations]\n",
    "\n",
    "    return hybrid_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Hits:\n",
      "518 / 1141\n",
      "Precision:\n",
      "0.6980484713897848\n",
      "Recall:\n",
      "0.9956178410274211\n",
      "F1:\n",
      "0.7791715983577455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hybrid_recommendations = join_recommendations(user_recommendations, content_rec_per_community)\n",
    "\n",
    "community_hits, precisions, recall, f1 = calculate_precision(community_test_dfs, hybrid_recommendations, communities)\n",
    "print(\"Community Hits:\")\n",
    "print(community_hits)\n",
    "print(\"Precision:\")\n",
    "print(precisions)\n",
    "print(\"Recall:\")\n",
    "print(recall)\n",
    "print(\"F1:\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the most popular restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Hits:\n",
      "49 / 1175\n",
      "Precision:\n",
      "0.01735214211531974\n",
      "Recall:\n",
      "0.047409686394150635\n",
      "F1:\n",
      "0.025310094831552596\n"
     ]
    }
   ],
   "source": [
    "pop_recommendations = {}\n",
    "\n",
    "for community_id, trainset in community_trainsets.items():\n",
    "    popular_businesses = popular_recommendations(trainset, 3)\n",
    "    pop_recommendations[community_id] = {}  \n",
    "    for user_id in trainset.ur:\n",
    "        pop_recommendations[community_id][trainset.to_raw_uid(user_id)] = popular_businesses\n",
    "\n",
    "\n",
    "community_hits, precisions, recall, f1 = calculate_precision(community_test_dfs, pop_recommendations, communities)\n",
    "print(\"Community Hits:\")\n",
    "print(community_hits)\n",
    "print(\"Precision:\")\n",
    "print(precisions)\n",
    "print(\"Recall:\")\n",
    "print(recall)\n",
    "print(\"F1:\")\n",
    "print(f1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
