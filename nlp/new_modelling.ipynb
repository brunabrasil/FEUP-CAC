{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from xgboost import XGBClassifier\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load review sentiment data\n",
    "\n",
    "review_df = pd.read_csv('data/review_sentiment.csv')\n",
    "\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "    0: 'bag_of_words',\n",
    "    1: 'one_hot',\n",
    "    2: 'n_grams',\n",
    "    3: 'tf_idf',\n",
    "    4: 'word2vec',\n",
    "    5: 'combined_features'\n",
    "}\n",
    "# Load all feature sets\n",
    "features = {}\n",
    "for key, feature_name in feature_set.items():\n",
    "    if key == 4:\n",
    "        features[key] = np.load('features/' + feature_name + '.npy')\n",
    "    else:\n",
    "        features[key] = sparse.load_npz('features/' + feature_name + '.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target labels\n",
    "\n",
    "y = review_df['sentiment'].to_numpy()\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec features for grid search\n",
    "word2vec_features = features[4]\n",
    "bow_features = features[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets using word2vec features\n",
    "X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(word2vec_features, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers\n",
    "\n",
    "classifiers = {\n",
    "    'gaussian_nb': GaussianNB(),\n",
    "    'multino_nb': MultinomialNB(),\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'svm': SVC(),\n",
    "    'perceptron': Perceptron(tol=1e-3, random_state=0),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    # 'gaussian_nb': {},\n",
    "    # 'decision_tree': {\n",
    "    #     'max_depth': [None, 10, 20]\n",
    "    # },\n",
    "    # 'random_forest': {\n",
    "    #     'n_estimators': [100, 200],\n",
    "    #     'max_depth': [None, 10]\n",
    "    # },\n",
    "    # 'svm': {\n",
    "    #     'C': [0.1, 1.0],\n",
    "    #     'kernel': ['linear', 'rbf']\n",
    "    # },\n",
    "    # 'perceptron': {\n",
    "    #     'alpha': [0.0001, 0.001],\n",
    "    #     'penalty': [None, 'l2']\n",
    "    # },\n",
    "    'xgb': {\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [100, 200]\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'C': [0.1, 1.0],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert numpy arrays to pandas Series\n",
    "y_train_series = pd.Series(y_train)\n",
    "y_test_series = pd.Series(y_test)\n",
    "\n",
    "# Remap labels: -1 -> 0, 0 -> 1, 1 -> 2\n",
    "y_train_mapped = y_train_series.map({-1: 0, 0: 1, 1: 2})\n",
    "y_test_mapped = y_test_series.map({-1: 0, 0: 1, 1: 2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = {}\n",
    "\n",
    "# # Cross-validation for each classifier\n",
    "# for clf_name, clf in classifiers.items():\n",
    "#     print(f\"Cross-validating {clf_name}...\")\n",
    "#     if clf_name == 'xgb':\n",
    "#         cv_results = cross_validate(clf, X_train_w2v, y_train_mapped, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], cv=5)\n",
    "\n",
    "#     else:\n",
    "#         cv_results = cross_validate(clf, X_train_w2v, y_train, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], cv=5)\n",
    "\n",
    "#     cv_scores[clf_name] = cv_results\n",
    "\n",
    "# for clf_name, cv_result in cv_scores.items():\n",
    "#     print(f\"Classifier: {clf_name}\")\n",
    "#     print(\"Accuracy:\", cv_result['test_accuracy'].mean())\n",
    "#     print(\"Precision (Macro):\", cv_result['test_precision_macro'].mean())\n",
    "#     print(\"Recall (Macro):\", cv_result['test_recall_macro'].mean())\n",
    "#     print(\"F1 Score (Macro):\", cv_result['test_f1_macro'].mean())\n",
    "#     print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_estimators = {}\n",
    "\n",
    "# # Apply grid search to each classifier using word2vec features\n",
    "# for clf_name, clf in classifiers.items():\n",
    "#     print(f\"Grid search for {clf_name}\")\n",
    "#     param_grid = param_grids[clf_name]\n",
    "#     if clf_name == 'xgb':\n",
    "#         grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=3)\n",
    "#         grid_search.fit(X_train_w2v, y_train_mapped)\n",
    "#     else:\n",
    "#         grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=3)\n",
    "#         grid_search.fit(X_train_w2v, y_train)\n",
    "#     best_estimators[clf_name] = grid_search.best_estimator_\n",
    "#     print(f\"Best parameters for {clf_name}: {grid_search.best_params_}\")\n",
    "#     print(f\"Best accuracy for {clf_name}: {grid_search.best_score_}\")\n",
    "#     print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifiers = {\n",
    "    'xgb': XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=200),\n",
    "    'gaussian_nb': GaussianNB(),\n",
    "    'multinomial_nb': MultinomialNB(),\n",
    "    'decision_tree': DecisionTreeClassifier(max_depth=10),\n",
    "    'random_forest': RandomForestClassifier(max_depth=10, n_estimators=200),\n",
    "    'svm': SVC(C=1.0, kernel='rbf'),\n",
    "    'perceptron': Perceptron(tol=1e-3, random_state=0, alpha=0.0001, penalty=None),\n",
    "    'logistic_regression': LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loop through each feature set\n",
    "for feature_key, feature_name in feature_set.items():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features[feature_key], y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Oversample to balance the classes\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # change -1 to 2 because of xbg\n",
    "    y_train_resampled_series = pd.Series(y_train_resampled)\n",
    "    y_test_series = pd.Series(y_test)\n",
    "    y_train_resampled_mapped = y_train_resampled_series.map({-1: 0, 0: 1, 1: 2})\n",
    "    y_test_mapped = y_test_series.map({-1: 0, 0: 1, 1: 2})\n",
    "\n",
    "\n",
    "    print(f\"Using {feature_name} features:\")\n",
    "    \n",
    "    # Loop through each classifier\n",
    "    for clf_name, clf in best_classifiers.items():\n",
    "        print(f\"Training {clf_name} with {feature_name} features...\")\n",
    "        \n",
    "        \n",
    "        # Convert sparse to dense if necessary\n",
    "        if feature_key != 4 and clf_name in ['gaussian_nb', 'multinomial_nb', 'perceptron']:\n",
    "            X_train_dense = X_train_resampled.toarray()\n",
    "            X_test_dense = X_test.toarray()\n",
    "            clf.fit(X_train_dense, y_train_resampled)\n",
    "            y_pred = clf.predict(X_test_dense)\n",
    "        else:\n",
    "            if clf_name == 'xgb':\n",
    "                clf.fit(X_train_resampled, y_train_resampled_mapped)\n",
    "            else:\n",
    "                clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        if clf_name == 'xgb':\n",
    "            acc = accuracy_score(y_test_mapped, y_pred)\n",
    "        else:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Accuracy of {clf_name} with {feature_name} features: {acc}\")\n",
    "    \n",
    "    print(\"---------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
